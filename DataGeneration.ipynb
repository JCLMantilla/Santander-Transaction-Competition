{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports are ready!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('Imports are ready!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # **Loading Datasets**\n",
    "\n",
    " As you can see in both sets we contain 20k examples, each containing it's information of its \"ID_code\" and 200 numerical features. It is important to note that the training set contains an aditional column containing the binary target for each example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us load the training and the test set, please wait.\n",
      "Shape of training set: (200000, 202)\n",
      "Shape of testing set: (200000, 201)\n"
     ]
    }
   ],
   "source": [
    "print(\"Let us load the training and the test set, please wait.\")\n",
    "train=pd.read_csv('/Users/juansmacbook/PycharmProjects/Santander_Transaction/santander_data/train.csv')\n",
    "test=pd.read_csv('/Users/juansmacbook/PycharmProjects/Santander_Transaction/santander_data/test.csv')\n",
    "print(\"Shape of training set: \"+str(train.shape))\n",
    "print(\"Shape of testing set: \"+str(test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **\"Magic\" and synthetic examples in the test dataset**\n",
    "This competition is interesting because people in the forums discovered that the 50% of the test set is synthetic! The key to distinguish the real testing examples from the fake ones is checking whether the value of a certain feature isn't repeated in another training example. Therefore, only the examples that have *at least one unique value in any of their features* are considered to be real!\n",
    "\n",
    "This of course wasn't discovered by me, this is what the community calls \"Magic\" when it comes to kaggle competitions. I will elaborate further on why this is really important for the model.\n",
    "\n",
    "In this order of ideas, my next task will be to filter out the fake testing examples and prove to you that this is actually the case. We should be able to notice that 10.000  training examples are real and 10.000 are fake!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"Here we define a function that inputs a column from a data frame and returns a list of the values that only appear one time in that data set\"\"\"\n",
    "\n",
    "def unique_values(column):\n",
    "    count=column.value_counts()\n",
    "    return count.index[count==1]\n",
    "\n",
    "\"\"\"We are going to check what examples in test set are real or not by doing value counts, examples whose variables arent repeated in the whole test set are considered to be real!\"\"\"\n",
    "\n",
    "def feature_uniqueness(data_frame=test): # This function inputs the TEST DATASET and returns its \"extended\" version that says which feature is unique\n",
    "\n",
    "    for column in data_frame.columns[1:]: #Notice that we are dropping the first column since we don't care bout ID\n",
    "        new_column=pd.Series(\n",
    "            data=data_frame[column].isin(unique_values(data_frame[column])).to_numpy(),\n",
    "            name=column+'_unique?'\n",
    "        )\n",
    "        data_frame=pd.concat([data_frame,new_column],axis=1)\n",
    "    return data_frame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n\n     var_7   var_8  ...  var_190_unique?  var_191_unique?  var_192_unique?  \\\n0  18.2675  2.1337  ...            False            False            False   \n1  18.6316 -4.4131  ...            False            False            False   \n2  20.2537  1.5233  ...            False            False            False   \n3  20.5660  3.3755  ...            False            False            False   \n4  10.6048  2.9890  ...            False            False            False   \n\n   var_193_unique?  var_194_unique?  var_195_unique?  var_196_unique?  \\\n0            False            False            False            False   \n1            False            False            False            False   \n2            False            False            False            False   \n3            False            False            False             True   \n4            False            False            False            False   \n\n   var_197_unique?  var_198_unique?  var_199_unique?  \n0            False            False            False  \n1            False            False            False  \n2            False            False            False  \n3             True            False            False  \n4            False            False            False  \n\n[5 rows x 401 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>var_0</th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>var_3</th>\n      <th>var_4</th>\n      <th>var_5</th>\n      <th>var_6</th>\n      <th>var_7</th>\n      <th>var_8</th>\n      <th>...</th>\n      <th>var_190_unique?</th>\n      <th>var_191_unique?</th>\n      <th>var_192_unique?</th>\n      <th>var_193_unique?</th>\n      <th>var_194_unique?</th>\n      <th>var_195_unique?</th>\n      <th>var_196_unique?</th>\n      <th>var_197_unique?</th>\n      <th>var_198_unique?</th>\n      <th>var_199_unique?</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>11.0656</td>\n      <td>7.7798</td>\n      <td>12.9536</td>\n      <td>9.4292</td>\n      <td>11.4327</td>\n      <td>-2.3805</td>\n      <td>5.8493</td>\n      <td>18.2675</td>\n      <td>2.1337</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>8.5304</td>\n      <td>1.2543</td>\n      <td>11.3047</td>\n      <td>5.1858</td>\n      <td>9.1974</td>\n      <td>-4.0117</td>\n      <td>6.0196</td>\n      <td>18.6316</td>\n      <td>-4.4131</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>5.4827</td>\n      <td>-10.3581</td>\n      <td>10.1407</td>\n      <td>7.0479</td>\n      <td>10.2628</td>\n      <td>9.8052</td>\n      <td>4.8950</td>\n      <td>20.2537</td>\n      <td>1.5233</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>8.5374</td>\n      <td>-1.3222</td>\n      <td>12.0220</td>\n      <td>6.5749</td>\n      <td>8.8458</td>\n      <td>3.1744</td>\n      <td>4.9397</td>\n      <td>20.5660</td>\n      <td>3.3755</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>11.7058</td>\n      <td>-0.1327</td>\n      <td>14.1295</td>\n      <td>7.7506</td>\n      <td>9.1035</td>\n      <td>-8.5848</td>\n      <td>6.8595</td>\n      <td>10.6048</td>\n      <td>2.9890</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 401 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n\n     var_7   var_8  ...  var_190_unique?  var_191_unique?  var_192_unique?  \\\n0  18.2675  2.1337  ...            False            False            False   \n1  18.6316 -4.4131  ...            False            False            False   \n2  20.2537  1.5233  ...            False            False            False   \n3  20.5660  3.3755  ...            False            False            False   \n4  10.6048  2.9890  ...            False            False            False   \n\n   var_193_unique?  var_194_unique?  var_195_unique?  var_196_unique?  \\\n0            False            False            False            False   \n1            False            False            False            False   \n2            False            False            False            False   \n3            False            False            False             True   \n4            False            False            False            False   \n\n   var_197_unique?  var_198_unique?  var_199_unique?  \n0            False            False            False  \n1            False            False            False  \n2            False            False            False  \n3             True            False            False  \n4            False            False            False  \n\n[5 rows x 401 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>var_0</th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>var_3</th>\n      <th>var_4</th>\n      <th>var_5</th>\n      <th>var_6</th>\n      <th>var_7</th>\n      <th>var_8</th>\n      <th>...</th>\n      <th>var_190_unique?</th>\n      <th>var_191_unique?</th>\n      <th>var_192_unique?</th>\n      <th>var_193_unique?</th>\n      <th>var_194_unique?</th>\n      <th>var_195_unique?</th>\n      <th>var_196_unique?</th>\n      <th>var_197_unique?</th>\n      <th>var_198_unique?</th>\n      <th>var_199_unique?</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>11.0656</td>\n      <td>7.7798</td>\n      <td>12.9536</td>\n      <td>9.4292</td>\n      <td>11.4327</td>\n      <td>-2.3805</td>\n      <td>5.8493</td>\n      <td>18.2675</td>\n      <td>2.1337</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>8.5304</td>\n      <td>1.2543</td>\n      <td>11.3047</td>\n      <td>5.1858</td>\n      <td>9.1974</td>\n      <td>-4.0117</td>\n      <td>6.0196</td>\n      <td>18.6316</td>\n      <td>-4.4131</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>5.4827</td>\n      <td>-10.3581</td>\n      <td>10.1407</td>\n      <td>7.0479</td>\n      <td>10.2628</td>\n      <td>9.8052</td>\n      <td>4.8950</td>\n      <td>20.2537</td>\n      <td>1.5233</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>8.5374</td>\n      <td>-1.3222</td>\n      <td>12.0220</td>\n      <td>6.5749</td>\n      <td>8.8458</td>\n      <td>3.1744</td>\n      <td>4.9397</td>\n      <td>20.5660</td>\n      <td>3.3755</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>11.7058</td>\n      <td>-0.1327</td>\n      <td>14.1295</td>\n      <td>7.7506</td>\n      <td>9.1035</td>\n      <td>-8.5848</td>\n      <td>6.8595</td>\n      <td>10.6048</td>\n      <td>2.9890</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 401 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is our new data frame containing 200 extra features that tell us which feature is unique in each column for every training example\"\"\"\n",
    "temporal_df=feature_uniqueness()\n",
    "temporal_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Proof that 50% of data set is fake!**\n",
    "Just as previously mentioned, the only examples that are we going to consider to be non-synthetic will be those have at least one unique value on their features, the ones that don't have any will be considered as fake. We can easily filter out the real and the fake ones via a simple condition.\n",
    "Using this condition we are going to split the training set into real and fake examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0         False\n1         False\n2         False\n3          True\n4         False\n          ...  \n199995     True\n199996     True\n199997    False\n199998    False\n199999     True\nLength: 200000, dtype: bool"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In each example we are checking whether if any of their lats 200 features has a true statement\n",
    "condition=temporal_df[temporal_df.columns[201:]].any(axis=1)\n",
    "condition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._\n",
      "Just as mentioned in the forums, 50% of test data is fake!\n",
      "False    100000\n",
      "True     100000\n",
      "dtype: int64\n",
      "_.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('_.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._')\n",
    "print('Just as mentioned in the forums, 50% of test data is fake!')\n",
    "print(\n",
    "    temporal_df[temporal_df.columns[201:]].any(axis=1).value_counts()\n",
    ")\n",
    "print('_.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._')\n",
    "\n",
    "\n",
    "#Now we can split the dataset in the real part and the fake part\n",
    "\n",
    "real_test_examples==temporal_df[condition==True]\n",
    "fake_test_examples=temporal_df[condition==False]\n",
    "\n",
    "#let us delete x_test to save some memory since we already have it splitted in two parts\n",
    "del temporal_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#We create a new variable that says if an example is real or not\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m temporal_df\u001B[38;5;241m.\u001B[39mdrop(\u001B[43mx_test\u001B[49m\u001B[38;5;241m.\u001B[39mcolumns[\u001B[38;5;241m201\u001B[39m:\u001B[38;5;241m401\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      4\u001B[0m                  inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\u001B[38;5;66;03m#Cambiar por TRUE DESPUESSSS\u001B[39;00m\n\u001B[1;32m      5\u001B[0m                  )\n\u001B[1;32m      6\u001B[0m temporal_df[\u001B[38;5;241m7\u001B[39m:\u001B[38;5;241m8\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "#We create a new variable that says if an example is real or not\n",
    "\n",
    "temporal_df.drop(x_test.columns[201:401], axis=1,\n",
    "                 inplace=True#Cambiar por TRUE DESPUESSSS\n",
    "                 )\n",
    "temporal_df[7:8]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_test[col+'_unique']= x_test[col].isin( unique_values(x_test[col]) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////////////////////////////////////\n",
      "Just as mentioned in the forums, 50% of test data is fake!\n",
      "False    100000\n",
      "True     100000\n",
      "Name: real, dtype: int64\n",
      "/////////////////////////////////////////////////////////\n",
      "/////////////////////////////////////////////////////////\n",
      "/////////////////////////////////////////////////////////\n",
      "Shape after concatenating: (300000, 201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n",
      "/var/folders/13/z6c3b3d50nnbcf08brkd87dw0000gn/T/ipykernel_20316/2412576041.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_test_examples[column+'_unique']= 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 38>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# We append to the dataset 200 new features containing what values are unique\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m x_train\u001B[38;5;241m.\u001B[39mcolumns[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[0;32m---> 39\u001B[0m     uniques_count\u001B[38;5;241m=\u001B[39m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue_counts\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     x_train[column\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_unique\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39mx_train[column]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m uniques_count[x]\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     41\u001B[0m     fake_test_examples[column\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_unique\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/Santander_Transaction/venv/lib/python3.8/site-packages/pandas/core/series.py:1740\u001B[0m, in \u001B[0;36mSeries.to_dict\u001B[0;34m(self, into)\u001B[0m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;66;03m# GH16122\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m into_c \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mstandardize_mapping(into)\n\u001B[0;32m-> 1740\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minto_c\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaybe_box_native\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Santander_Transaction/venv/lib/python3.8/site-packages/pandas/core/series.py:1740\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;66;03m# GH16122\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m into_c \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mstandardize_mapping(into)\n\u001B[0;32m-> 1740\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m into_c((k, maybe_box_native(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems())\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# We are going to concatenate the train set and the real training examples into x_train to do a value count later\n",
    "# We check what values are uniques in both training set and real training set\n",
    "x_train=pd.concat( [train.drop(['target'],axis=1), real_test_examples.drop(['real'], axis=1)] , axis=0)\n",
    "x_train.reset_index(inplace=True) #lets reset index to avoid problems later\n",
    "x_train.drop(['index'], axis=1, inplace=True)\n",
    "print('Shape after concatenating: '+str(x_train.shape))\n",
    "# We append to the dataset 200 new features containing what values are unique\n",
    "for column in x_train.columns[1:]:\n",
    "    uniques_count=x_train[column].value_counts().to_dict()\n",
    "    x_train[column+'_unique']=x_train[column].apply(lambda x: 1 if uniques_count[x]==1 else 0).values\n",
    "    fake_test_examples[column+'_unique']= 0\n",
    "print('Finished!')\n",
    "#We create the final test set containing all unique value counts!!!!!!\n",
    "fake_test_examples.drop(['real'], axis=1, inplace=True)\n",
    "x_test=pd.concat([x_train[:][200000:],fake_test_examples])\n",
    "\n",
    "#We create the final training set containing value counts!\n",
    "x_train=x_train[:][:200000]\n",
    "\n",
    "\n",
    "print('Ready!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}